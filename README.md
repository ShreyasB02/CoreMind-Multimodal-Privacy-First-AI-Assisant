ADVANCED_SIRI
---
> A privacy-first, multimodal memory assistant inspired by Apple Intelligence.
> Built to run locally, summarize your life, and reflect â€” just like the next-gen Siri.

![Advanced_Siri demo screenshot](demo/screenshot.png)
---

## âœ¨ Features

| Capability                       | Description                                                                                             |
| -------------------------------- | ------------------------------------------------------------------------------------------------------- |
| ğŸ“¸ **Image & Screenshot Memory** | Uploads screenshots or images and auto-generates visual captions using BLIP                             |
| ğŸ¤ **Voice Memory**              | Transcribes user voice notes with Whisper and stores them as memories                                   |
| ğŸ§  **Multimodal Embedding**      | All memories are embedded using SBERT and indexed via FAISS                                             |
| ğŸ” **Ask Your Memory**           | Natural language search over your stored experiences using LangGraph                                    |
| ğŸ“… **Weekly Reflections**        | Automatically clusters and summarizes your memories using local LLMs (Ollama or Apple Foundation Model) |
| ğŸ›¡ï¸ **Privacy-First**            | Entire pipeline runs locally (no cloud dependencies), with optional CoreML / Foundation Model support   |

---

## Architecture Overview

```
          ğŸ“· / ğŸ¤ User Inputs
                â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Caption / Transcribe (BLIP, Whisper) â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Embedding (BERT)  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
     FAISS + SQLite Storage (Memory)
                â†“
     LangGraph Query + Reflection Agent
                â†“
       ğŸ” Ask | ğŸ“… Summarize | ğŸ§  Reflect
```

---

## ğŸ“¦ Tech Stack

* **Frontend**: Streamlit
* **Multimodal AI**: BLIP, Whisper (via Faster-Whisper), Sentence Transformers
* **Retrieval**: FAISS, SQLite
* **Reasoning**: LangGraph
* **Summarization**: Ollama (`mistral`, `llama3`) or Apple Foundation Model (Swift)
* **Tags & Reflection**: KMeans + LLM
* **Future Ready**: SwiftUI port planned with CoreML + Apple Foundation API

---

## ğŸš€ Demo

[https://user-images.githubusercontent.com/.../sirimemory-demo.mp4](https://user-images.githubusercontent.com/.../sirimemory-demo.mp4)
*(Upload an image or voice note â†’ Ask Advanced_Siri â†’ See weekly reflections)*

---

## ğŸ’» Run Locally

### 1. Clone the repo

```bash
git clone https://github.com/shreyasbattula/sirimemory.git
cd sirimemory
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

### 3. Pull Ollama model

```bash
ollama pull mistral  # or llama3
```

### 4. Run the app

```bash
bash run_app.sh
```

---

## ğŸ” `.env` Example

```env
SQLITE_DB_PATH=data/memory_meta.sqlite
```

---

## ğŸ”§ Folder Structure

```
Advanced_Siri
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Streamlit UI
â”‚   â”œâ”€â”€ memory_manager.py    # Store/retrieve memory
â”‚   â”œâ”€â”€ langgraph_flow.py    # LangGraph memory reasoning
â”‚   â”œâ”€â”€ reflection.py        # Weekly reflection summarizer
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ vision_model.py      # BLIP caption generator
â”‚   â”œâ”€â”€ embedding_model.py   # Sentence transformer
â”‚   â”œâ”€â”€ whisper_model.py     # Faster Whisper wrapper
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ memory_meta.sqlite
â”‚   â”œâ”€â”€ memory_index.faiss
â”œâ”€â”€ .env
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_app.sh
â”œâ”€â”€ README.md
```

---

## ğŸ§© Roadmap

* [x] Multimodal input (image + audio)
* [x] Local embedding & indexing
* [x] LangGraph query flow
* [x] Ollama-based summarization
* [x] Weekly memory reflection storage
* [ ] SwiftUI version using Apple Foundation Model API
* [ ] Convert BLIP & Whisper to CoreML
* [ ] Publish as Siri Shortcut or iOS widget

---

## ğŸ’¡ Inspiration

Advanced_Siri is inspired by:

* Apple Intelligence (WWDC 2025)
* Humane AI Pin
* Personal memory agents from Rewind.ai & Mem.ai
* LangGraph and Self-Reflective RAG

---

## ğŸ‘¨â€ğŸ’» Author

**Shreyas Battula**
ğŸ“ GenAI Intern @ Nokia | MS CS @ UC Riverside
ğŸ”— [LinkedIn](https://www.linkedin.com/in/shreyas-battula--688360196) | ğŸ§  [GitHub](https://github.com/ShreyasB02) | âœ‰ï¸ [shreyasb2002@gmail.com](mailto:shreyasb2002@gmail.com)

---

